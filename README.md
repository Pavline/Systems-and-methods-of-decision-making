# Systems-and-methods-of-decision-making
# Тема: «Метрические	алгоритмы	классификации»

Метрические алгоритмы основываются на гипотезе компактоности, в которой сказано, что схожим объектам соответствуют схожие ответы. 

ρ: X×X→ℝ

ρ (X, X') - это мера близости, которая показывает насколько X похож на X'.

Метрические алгоритмы классификации это:
- KNN
- KwNN
- PW
- PF
- STOLP


## Алгоритм	ближайших	соседей
### Алгоритм 	k ближайших	соседей	- KNN
Алгоритм анализа k ближайших соседей. 
KNN относит классифицируемый объект к тому классу, элементов которого больше среди k ближайших соседей.

![Иллюстрация к проекту](https://github.com/Pavline/Systems-and-methods-of-decision-making/blob/master/knn_tr.png)
Недостатки: 
- Нужно хранить всю обучающую выборку целиком, а это неэффективный расход памяти.
- Алгоритм не устойчив к погрешностям и это влияет на точность результатов

Достоинства: 
- Простота реализации
- Несмотря на неустойчивость к погрешностям, можно получить хороший результат.


• Выбрать	оптимальное	значение	k по	критерию	скользящего	контроля	LOO и	построить	график	зависимости	LOO(k).
• Реализовать	алгоритм	k взвешенных	ближайших	соседей	– kwNN.
• Выбрать	оптимальные	значение	k и	q (параметра	весовой	функции	qi)	по	критерию	скользящего	контроля	LOO и	построить	график	зависимости	LOO(k,	h).
• Сравнить	качество	алгоритмов	kNN и	kwNN.
• Построить	карту	классификации	для	рассматриваемых	методов.
• Привести пример,	показывающий	преимущество	метода kwNNнад kNN.

## Метод парзеновского	окна
• Реализовать	метод	парзеновского	окна.
• Рассмотреть	несколько	видов	ядер,	для	каждого	из	них	построить	карту	классификации,	оценить	качество,	подобрать.
• оптимальное	значение	ширины	окна	h по	критерию	скользящего	контроля	LOO.
• Сравнить	качество	построенных	алгоритмов	между	собой	и	с	ранее	реализованными методами.

## Метод	потенциальных	функций
• Реализовать	метод	потенциальных	функций	с	фиксированнойшириной	окна.
• Сделать	чертеж	демонстрирующий	особенность	метода	(например,	выделить	с	помощью	размера	и	яркости	объекты	с	более	высоким	потенциалом).
• Рассмотреть	несколько	видов	ядер,	для	каждого	из	них	построить	
карту	классификации,	оценить	качество.
• Сравнить	качество	построенного	алгоритма	классификации с	ранее	реализованными методами.

##  Отбор	эталонных	объектов
• Построить	график	отступов	для	объектов	обучения	относительно	произвольного	метрического	классификатора.
• С	помощью	алгоритма	«крутого	склона»	отобрать	шумовые	объекты	–выбросы.
• Реализовать	алгоритм	STOLP для	отбора	опорных	объектов.
• Сравнить	качество	и	скорость	работы	алгоритма	классификации	до	и	после	отбора	объектов	с	помощью	алгоритма	STOLP.


# Тема:	«Байесовские	алгоритмы	классификации»

## Линии	уровня	нормального	распределения
Данные: Центр	и	ковариационная	матрица.
• Отобразить	на	графике	линии	уровня	нормального	распределения	с	указанием	на	них	значения	плотности	распределения.
• Рассмотреть	все	особые	случаи.

## Наивный	нормальный	байесовский	классификатор
Данные: Реальные или	модельные.
• Реализовать	наивный	нормальный байесовский	классификатор.
• Сделать	чертеж, демонстрирующий	работу	данного	метода.	

## Подстановочный	алгоритм	(plug-in)
Данные: Реальные или	модельные.
• Реализовать	подстановочный	байесовский	алгоритм.
• Сделать	чертеж, демонстрирующий	работу	алгоритма.
• Рассмотреть	случаи,	когда	разделяющая	кривая	является:	параболой,	эллипсом	и	гиперболой.	

## Линейный	дискриминант	Фишера	– ЛДФ
Данные: Реальные или	модельные.
Язык	программирования:
• Реализовать	линейный	дискриминант	Фишера.
• Сделать	чертеж,	демонстрирующий	работу	алгоритма.
• Указать	на	преимущества	метода	по	сравнению	с	подстановочным	алгоритмом.	

## Сеть	радиальных	базисных	функций	– RBF сеть
Данные: Реальные или	модельные,	имеющие	в	каждом	классе	два	и	более	сгустка.
• Реализовать	EM-алгоритм	с	последовательным	добавлением	компонент.
• на	основе	EM-алгоритма	обучить	RBF-сеть.
• сделать	чертеж,	демонстрирующий	работу	алгоритма.	


# Тема	«Линейные	алгоритмы	классификации»
## ADALINE.	Правило	Хэбба	(персептрон	Розенблатта)
Данные: Реальные или	модельные.
• Реализовать	метод	стохастического	градиента	для	произвольной	функции	потерь.
• Реализовать	линейный	алгоритм	классификации	ADALINE.
• Построить	линейный	классификатор	с использованием	правила	Хебба	в	методе	стохастического	градиента.
• Сделать	чертежи, демонстрирующие	работу	алгоритмов.
• Сравнить	два	этих	метода.	

## Логистическая	регрессия
Данные: Реальные или	модельные.
• Обучить	алгоритм	логистической	регрессии с	помощью	метода	стохастического	градиента.
• Сделать	чертеж, демонстрирующий	работу	алгоритма.
• В зависимости	от	значения	апостериорной	вероятности	(принадлежности	объекта	к	классу)	раскрасить	чертеж	– чем	большее	значение	вероятности,	тем	темнее	цвет.
• Продемонстрировать	на	одном	графике	работу	реализованных	выше	алгоритмов.	

## Метод	опорных	векторов	– SVM.	ROC-кривая
Данные: Реальные или	модельные.
Язык	программирования: К +	kernlab
• С	помощью	библиотеки	kernlab для	языка	R релализовать	алгоритм	SVM.
• Реализовать алгоритм	построения	ROC-кривой и	вычисления	AUC.
• Продемонстрировать	работу	метода	для	случаев:	
o линейно	разделимой	выборки;
o линенейно	неразделимой	выборки с	малым	числом	объектов,	«мешающих» линейной	отделимости;
o линенейно	неразделимой	выборки с	средним числом	объектов,	«мешающих» линейной	отделимости.
